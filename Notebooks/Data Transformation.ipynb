{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "003243ae",
   "metadata": {},
   "source": [
    "# <center>Data Analysis & Transformation </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4827ea15",
   "metadata": {},
   "source": [
    "The purpose of this notebook is to analyze data and prepare it by joining multiple sources, picking up the right features, cleaning them and finally saving as a ready-to-go Azure ML Dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae97ae8d",
   "metadata": {},
   "source": [
    "I will use 5 data sources from the provided link:\n",
    "- <b>ontime_reporting (from both years - combined) </b>\n",
    "- <b>airport_weather (from both years - combined)</b> \n",
    "- <b>B43_aircraft_inventory </b> \n",
    "- <b>airport_list </b> \n",
    "- <b>airport_coordinates </b> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a085539",
   "metadata": {},
   "source": [
    "Based on my reaserch, there are the most common reasons for flight delays."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78dabf3f",
   "metadata": {},
   "source": [
    "<img src=\"https://www.claimcompass.eu/blog/content/images/2019/09/Why-is-My-Flight-Delayed-The-Main-Reasons.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "908e9cfe",
   "metadata": {},
   "source": [
    "Not all of them can be describe with available data. Here are the features I decided to use in that experiment.\n",
    "- ontime_reporting\n",
    "    - distance\n",
    "    - planned departure time\n",
    "    - day of week\n",
    "<br><br>\n",
    "- weather\n",
    "    - PRCP: Inches of precipitation for day (rain)\n",
    "    - SNOW: Inches of snowfall for day\n",
    "    - SNWD: Inches of snow on ground for day\n",
    "    - TMAX: Max temperature for day\n",
    "    - AWND: Max wind speed for day\n",
    "<br><br>    \n",
    "- B43_Aircraft_inventory\n",
    "    - number_of_seats\n",
    "<br><br>\n",
    "- airport_coordinates\n",
    "    - latitiude\n",
    "    - longitiude"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a73231d6",
   "metadata": {},
   "source": [
    "All files have been converted to Datasets (manually - using Azure ML Studio), so now let's prepare the final dataset the will be used to train the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba41549",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "588e142a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "\n",
    "import azureml.core\n",
    "from azureml.core import Workspace, Dataset, Datastore\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f894e904",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready to use Azure ML 1.44.0 to work with avanade-airline-delays\n"
     ]
    }
   ],
   "source": [
    "# Load the workspace from the saved config file\n",
    "\n",
    "ws = Workspace.from_config()\n",
    "print('Ready to use Azure ML {} to work with {}'.format(azureml.core.VERSION, ws.name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a915673",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets:\n",
      "\t airlines_processed_df_final version 1\n",
      "\t airlines_processed_dataset version 1\n",
      "\t airport_coordinates version 1\n",
      "\t aircraft_inventory version 1\n",
      "\t airport_list version 1\n",
      "\t airport_weather_2020 version 1\n",
      "\t airport_weather_2019 version 1\n",
      "\t ontime_reporting_2020 version 1\n",
      "\t ontime_reporting_2019 version 1\n"
     ]
    }
   ],
   "source": [
    "# Load all datasets\n",
    "\n",
    "print(\"Datasets:\")\n",
    "for dataset_name in list(ws.datasets.keys()):\n",
    "    dataset = Dataset.get_by_name(ws, dataset_name)\n",
    "    print(\"\\t\", dataset.name, 'version', dataset.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4264c71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "aircraft_inventory = Dataset.get_by_name(ws, name='aircraft_inventory')\n",
    "df_aircraft_inventory = aircraft_inventory.to_pandas_dataframe()\n",
    "\n",
    "airport_list = Dataset.get_by_name(ws, name='airport_list')\n",
    "df_airport_list = airport_list.to_pandas_dataframe()\n",
    "\n",
    "airport_weather_2020 = Dataset.get_by_name(ws, name='airport_weather_2020')\n",
    "df_airport_weather_2020 = airport_weather_2020.to_pandas_dataframe()\n",
    "\n",
    "airport_weather_2019 = Dataset.get_by_name(ws, name='airport_weather_2019')\n",
    "df_airport_weather_2019 = airport_weather_2019.to_pandas_dataframe()\n",
    "\n",
    "ontime_reporting_2020 = Dataset.get_by_name(ws, name='ontime_reporting_2020')\n",
    "df_ontime_reporting_2020 = ontime_reporting_2020.to_pandas_dataframe()\n",
    "\n",
    "ontime_reporting_2019 = Dataset.get_by_name(ws, name='ontime_reporting_2019')\n",
    "df_ontime_reporting_2019 = ontime_reporting_2019.to_pandas_dataframe()\n",
    "\n",
    "airport_coordinates = Dataset.get_by_name(ws, name='airport_coordinates')\n",
    "df_airport_coordinates = airport_coordinates.to_pandas_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ebeed45",
   "metadata": {},
   "source": [
    "Let's start by selecting the right features for each dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f67a3215",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# weather df // 2 DFs will be concatenated firts as all rows are makred with proper date\n",
    "df_airport_weather = pd.concat([df_airport_weather_2019, df_airport_weather_2020])\n",
    "df_airport_weather = df_airport_weather[['NAME', 'DATE', 'PRCP', 'SNOW', 'SNWD', 'TMAX', 'AWND']]\n",
    "\n",
    "# airport_list\n",
    "df_airport_list = df_airport_list[['ORIGIN_AIRPORT_ID', 'NAME']]\n",
    "\n",
    "# ontime_reporting\n",
    "df_ontime_reporting_2019 = df_ontime_reporting_2019[['MONTH', 'DAY_OF_MONTH', 'DAY_OF_WEEK', 'TAIL_NUM', 'ORIGIN_AIRPORT_ID',\n",
    "                                                    'DISTANCE','CRS_DEP_TIME' ,'DEP_DEL15']]\n",
    "\n",
    "df_ontime_reporting_2020 = df_ontime_reporting_2020[['MONTH', 'DAY_OF_MONTH', 'DAY_OF_WEEK', 'TAIL_NUM', 'ORIGIN_AIRPORT_ID',\n",
    "                                                    'DISTANCE','CRS_DEP_TIME' ,'DEP_DEL15']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b483867c",
   "metadata": {},
   "source": [
    "Now, let's prepare the onetime_reporting dfs, co they could be concatenated and merged with other datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1279a33b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add 'YEAR' columns and based on that 'DATE' columns\n",
    "df_ontime_reporting_2019['YEAR'] = 2019\n",
    "df_ontime_reporting_2020['YEAR'] = 2020\n",
    "\n",
    "#2019\n",
    "df_ontime_reporting_2019.rename(columns={'DAY_OF_MONTH': 'DAY'}, inplace = True)\n",
    "df_ontime_reporting_2019['DATE'] = pd.to_datetime(df_ontime_reporting_2019[['YEAR', 'MONTH', 'DAY']])\n",
    "\n",
    "#2020\n",
    "df_ontime_reporting_2020.rename(columns={'DAY_OF_MONTH': 'DAY'}, inplace = True)\n",
    "df_ontime_reporting_2020['DATE'] = pd.to_datetime(df_ontime_reporting_2020[['YEAR', 'MONTH', 'DAY']])\n",
    "\n",
    "# drop columns 'YEAR', 'MONTH' and 'DAY', as they are not needed anymore \n",
    "df_ontime_reporting_2019.drop(['YEAR','MONTH', 'DAY'], axis = 1, inplace = True)\n",
    "df_ontime_reporting_2020.drop(['YEAR','MONTH', 'DAY'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6957a462",
   "metadata": {},
   "source": [
    "Let's merge the two ontime_reporting dfs and join them with the rest of datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "44d24da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ontime_reporting = pd.concat([df_ontime_reporting_2019, df_ontime_reporting_2020])\n",
    "\n",
    "#join df_ontime_reporting with df_airport_list  in order to get airport names\n",
    "df_draft1 = pd.merge(df_ontime_reporting, df_airport_list, how = 'left', on = 'ORIGIN_AIRPORT_ID')\n",
    "\n",
    "#join above df with df_airport_weather\n",
    "df_draft2 = pd.merge(df_draft1, df_airport_weather, how = 'left', on = ['NAME', 'DATE'])\n",
    "\n",
    "#join above df with df_airport_coordinates\n",
    "\n",
    "#remove duplicates from df_airport_coordinates\n",
    "df_airport_coordinates.drop_duplicates(subset=['ORIGIN_AIRPORT_ID'], inplace = True)\n",
    "\n",
    "df_draft3 = pd.merge(df_draft2, df_airport_coordinates, how = 'left', on = 'ORIGIN_AIRPORT_ID')\n",
    "\n",
    "#join above df with df_aircraft_inventory to get the number of seats\n",
    "\n",
    "#remove duplicates from df_aircraft_inventory\n",
    "df_aircraft_inventory.drop_duplicates(subset=['TAIL_NUM'], inplace = True)\n",
    "\n",
    "df_final = pd.merge(df_draft3, df_aircraft_inventory, how = 'left', on = 'TAIL_NUM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fdf8df0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final_copy = df_final.copy()\n",
    "#df_final = df_final_copy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28517cd4",
   "metadata": {},
   "source": [
    "Let's display the final DF and process it further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "309790ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DAY_OF_WEEK</th>\n",
       "      <th>ORIGIN_AIRPORT_ID</th>\n",
       "      <th>DISTANCE</th>\n",
       "      <th>CRS_DEP_TIME</th>\n",
       "      <th>DEP_DEL15</th>\n",
       "      <th>PRCP</th>\n",
       "      <th>SNOW</th>\n",
       "      <th>SNWD</th>\n",
       "      <th>TMAX</th>\n",
       "      <th>AWND</th>\n",
       "      <th>LATITUDE</th>\n",
       "      <th>LONGITUDE</th>\n",
       "      <th>NUMBER_OF_SEATS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>9.304362e+06</td>\n",
       "      <td>9.304362e+06</td>\n",
       "      <td>9.304362e+06</td>\n",
       "      <td>9.304362e+06</td>\n",
       "      <td>9.051745e+06</td>\n",
       "      <td>7.191868e+06</td>\n",
       "      <td>4.846610e+06</td>\n",
       "      <td>4.705170e+06</td>\n",
       "      <td>7.192458e+06</td>\n",
       "      <td>7.193058e+06</td>\n",
       "      <td>9.304362e+06</td>\n",
       "      <td>9.304362e+06</td>\n",
       "      <td>8.825005e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.946717e+00</td>\n",
       "      <td>1.265165e+04</td>\n",
       "      <td>8.013792e+02</td>\n",
       "      <td>1.331048e+03</td>\n",
       "      <td>1.797580e-01</td>\n",
       "      <td>1.025322e-01</td>\n",
       "      <td>5.869697e-02</td>\n",
       "      <td>1.493159e-01</td>\n",
       "      <td>6.910917e+01</td>\n",
       "      <td>8.416456e+00</td>\n",
       "      <td>3.672162e+01</td>\n",
       "      <td>-9.414409e+01</td>\n",
       "      <td>1.289433e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.986160e+00</td>\n",
       "      <td>1.524566e+03</td>\n",
       "      <td>5.918103e+02</td>\n",
       "      <td>4.935397e+02</td>\n",
       "      <td>3.839858e-01</td>\n",
       "      <td>3.034343e-01</td>\n",
       "      <td>4.325924e-01</td>\n",
       "      <td>9.125906e-01</td>\n",
       "      <td>1.857393e+01</td>\n",
       "      <td>3.650529e+00</td>\n",
       "      <td>5.866546e+00</td>\n",
       "      <td>1.823289e+01</td>\n",
       "      <td>4.911599e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.013500e+04</td>\n",
       "      <td>3.100000e+01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-1.300000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-1.433444e+01</td>\n",
       "      <td>-1.766447e+02</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>1.129200e+04</td>\n",
       "      <td>3.690000e+02</td>\n",
       "      <td>9.130000e+02</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>5.600000e+01</td>\n",
       "      <td>5.820000e+00</td>\n",
       "      <td>3.343611e+01</td>\n",
       "      <td>-1.048797e+02</td>\n",
       "      <td>7.600000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.000000e+00</td>\n",
       "      <td>1.288900e+04</td>\n",
       "      <td>6.410000e+02</td>\n",
       "      <td>1.324000e+03</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>7.100000e+01</td>\n",
       "      <td>7.830000e+00</td>\n",
       "      <td>3.736278e+01</td>\n",
       "      <td>-8.790611e+01</td>\n",
       "      <td>1.430000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.000000e+00</td>\n",
       "      <td>1.393100e+04</td>\n",
       "      <td>1.035000e+03</td>\n",
       "      <td>1.739000e+03</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.000000e-02</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>8.400000e+01</td>\n",
       "      <td>1.051000e+01</td>\n",
       "      <td>4.077944e+01</td>\n",
       "      <td>-8.093583e+01</td>\n",
       "      <td>1.690000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>7.000000e+00</td>\n",
       "      <td>1.686900e+04</td>\n",
       "      <td>5.095000e+03</td>\n",
       "      <td>2.359000e+03</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>7.130000e+00</td>\n",
       "      <td>9.900000e+00</td>\n",
       "      <td>2.520000e+01</td>\n",
       "      <td>1.150000e+02</td>\n",
       "      <td>3.288000e+01</td>\n",
       "      <td>7.128556e+01</td>\n",
       "      <td>1.457303e+02</td>\n",
       "      <td>3.370000e+02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        DAY_OF_WEEK  ORIGIN_AIRPORT_ID      DISTANCE  CRS_DEP_TIME  \\\n",
       "count  9.304362e+06       9.304362e+06  9.304362e+06  9.304362e+06   \n",
       "mean   3.946717e+00       1.265165e+04  8.013792e+02  1.331048e+03   \n",
       "std    1.986160e+00       1.524566e+03  5.918103e+02  4.935397e+02   \n",
       "min    1.000000e+00       1.013500e+04  3.100000e+01  1.000000e+00   \n",
       "25%    2.000000e+00       1.129200e+04  3.690000e+02  9.130000e+02   \n",
       "50%    4.000000e+00       1.288900e+04  6.410000e+02  1.324000e+03   \n",
       "75%    6.000000e+00       1.393100e+04  1.035000e+03  1.739000e+03   \n",
       "max    7.000000e+00       1.686900e+04  5.095000e+03  2.359000e+03   \n",
       "\n",
       "          DEP_DEL15          PRCP          SNOW          SNWD          TMAX  \\\n",
       "count  9.051745e+06  7.191868e+06  4.846610e+06  4.705170e+06  7.192458e+06   \n",
       "mean   1.797580e-01  1.025322e-01  5.869697e-02  1.493159e-01  6.910917e+01   \n",
       "std    3.839858e-01  3.034343e-01  4.325924e-01  9.125906e-01  1.857393e+01   \n",
       "min    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00 -1.300000e+01   \n",
       "25%    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  5.600000e+01   \n",
       "50%    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  7.100000e+01   \n",
       "75%    0.000000e+00  3.000000e-02  0.000000e+00  0.000000e+00  8.400000e+01   \n",
       "max    1.000000e+00  7.130000e+00  9.900000e+00  2.520000e+01  1.150000e+02   \n",
       "\n",
       "               AWND      LATITUDE     LONGITUDE  NUMBER_OF_SEATS  \n",
       "count  7.193058e+06  9.304362e+06  9.304362e+06     8.825005e+06  \n",
       "mean   8.416456e+00  3.672162e+01 -9.414409e+01     1.289433e+02  \n",
       "std    3.650529e+00  5.866546e+00  1.823289e+01     4.911599e+01  \n",
       "min    0.000000e+00 -1.433444e+01 -1.766447e+02     0.000000e+00  \n",
       "25%    5.820000e+00  3.343611e+01 -1.048797e+02     7.600000e+01  \n",
       "50%    7.830000e+00  3.736278e+01 -8.790611e+01     1.430000e+02  \n",
       "75%    1.051000e+01  4.077944e+01 -8.093583e+01     1.690000e+02  \n",
       "max    3.288000e+01  7.128556e+01  1.457303e+02     3.370000e+02  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f2fb783d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DAY_OF_WEEK</th>\n",
       "      <th>TAIL_NUM</th>\n",
       "      <th>ORIGIN_AIRPORT_ID</th>\n",
       "      <th>DISTANCE</th>\n",
       "      <th>CRS_DEP_TIME</th>\n",
       "      <th>DEP_DEL15</th>\n",
       "      <th>DATE</th>\n",
       "      <th>NAME</th>\n",
       "      <th>PRCP</th>\n",
       "      <th>SNOW</th>\n",
       "      <th>SNWD</th>\n",
       "      <th>TMAX</th>\n",
       "      <th>AWND</th>\n",
       "      <th>LATITUDE</th>\n",
       "      <th>LONGITUDE</th>\n",
       "      <th>NUMBER_OF_SEATS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>N8694A</td>\n",
       "      <td>10397</td>\n",
       "      <td>83.0</td>\n",
       "      <td>1645</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2019-01-06</td>\n",
       "      <td>ATLANTA HARTSFIELD JACKSON INTERNATIONAL AIRPO...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>6.49</td>\n",
       "      <td>33.640833</td>\n",
       "      <td>-84.427222</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>N8970D</td>\n",
       "      <td>10397</td>\n",
       "      <td>83.0</td>\n",
       "      <td>1645</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2019-01-07</td>\n",
       "      <td>ATLANTA HARTSFIELD JACKSON INTERNATIONAL AIRPO...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>5.14</td>\n",
       "      <td>33.640833</td>\n",
       "      <td>-84.427222</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>N820AY</td>\n",
       "      <td>10397</td>\n",
       "      <td>83.0</td>\n",
       "      <td>1645</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2019-01-08</td>\n",
       "      <td>ATLANTA HARTSFIELD JACKSON INTERNATIONAL AIRPO...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8.05</td>\n",
       "      <td>33.640833</td>\n",
       "      <td>-84.427222</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   DAY_OF_WEEK TAIL_NUM  ORIGIN_AIRPORT_ID  DISTANCE  CRS_DEP_TIME  DEP_DEL15  \\\n",
       "0            7   N8694A              10397      83.0          1645        0.0   \n",
       "1            1   N8970D              10397      83.0          1645        0.0   \n",
       "2            2   N820AY              10397      83.0          1645        0.0   \n",
       "\n",
       "        DATE                                               NAME  PRCP  SNOW  \\\n",
       "0 2019-01-06  ATLANTA HARTSFIELD JACKSON INTERNATIONAL AIRPO...   0.0   0.0   \n",
       "1 2019-01-07  ATLANTA HARTSFIELD JACKSON INTERNATIONAL AIRPO...   0.0   0.0   \n",
       "2 2019-01-08  ATLANTA HARTSFIELD JACKSON INTERNATIONAL AIRPO...   0.0   0.0   \n",
       "\n",
       "   SNWD  TMAX  AWND   LATITUDE  LONGITUDE  NUMBER_OF_SEATS  \n",
       "0   0.0  69.0  6.49  33.640833 -84.427222             50.0  \n",
       "1   0.0  69.0  5.14  33.640833 -84.427222             50.0  \n",
       "2   0.0  65.0  8.05  33.640833 -84.427222             50.0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "41712e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove not needed columns\n",
    "df_final.drop(columns = ['NAME', 'DATE', 'ORIGIN_AIRPORT_ID', 'TAIL_NUM'], inplace = True)\n",
    "\n",
    "#convert column 'DEP_DEL15' to int and change its name to 'TARGET'. Remove rows that doesn't equal 1 or 0\n",
    "df_final = df_final[(df_final['DEP_DEL15'] == 1.0) | (df_final['DEP_DEL15'] == 0.0)]\n",
    "df_final = df_final.astype({'DEP_DEL15': 'int32'})\n",
    "df_final.rename(columns = {'DEP_DEL15': 'TARGET'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c22a1d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace all the nulls with column's median\n",
    "df_final['PRCP'].fillna(df_final['PRCP'].median(), inplace = True)\n",
    "df_final['SNOW'].fillna(df_final['SNOW'].median(), inplace = True)\n",
    "df_final['SNWD'].fillna(df_final['SNWD'].median(), inplace = True)\n",
    "df_final['TMAX'].fillna(df_final['TMAX'].median(), inplace = True)\n",
    "df_final['AWND'].fillna(df_final['AWND'].median(), inplace = True)\n",
    "df_final['NUMBER_OF_SEATS'].fillna(df_final['NUMBER_OF_SEATS'].median(), inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a8718858",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a column that categorizes the values into four labels: night, morning, afternoon, evening.\n",
    "#Later, I will use one-hot-encoding method to split the values into separate columns.\n",
    "#original column 'CRS_DEP_TIME' will be removed\n",
    "\n",
    "def dep_time(x):\n",
    "    \n",
    "    if x < 600:\n",
    "        return 'NIGHT'\n",
    "    elif x >= 600 and x < 1200:\n",
    "        return 'MORNING'\n",
    "    elif x >= 1200 and x < 1800:\n",
    "        return 'AFTERNOON'\n",
    "    else:\n",
    "        return 'EVENING'\n",
    "        \n",
    "#apply function\n",
    "df_final['DEP_TIME'] = df_final['CRS_DEP_TIME'].apply(lambda x: dep_time(x))\n",
    "\n",
    "#one-hot encoding\n",
    "df_onehot = pd.get_dummies(df_final['DEP_TIME'], prefix  = \"DEP_TIME\")\n",
    "\n",
    "#merge with df_final\n",
    "df_final = df_final.join(df_onehot)\n",
    "\n",
    "#remove not needed columns\n",
    "df_final.drop(columns = ['CRS_DEP_TIME', 'DEP_TIME'], inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91198b35",
   "metadata": {},
   "source": [
    "I will also aply the one-hot encoding method to column 'DAY_OF_WEEK'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d57d7078",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_onehot_days = pd.get_dummies(df_final['DAY_OF_WEEK'], prefix  = \"DAY_OF_WEEK\")\n",
    "\n",
    "#merge with df_final\n",
    "df_final = df_final.join(df_onehot_days)\n",
    "\n",
    "#remove oryginal column\n",
    "df_final.drop(columns = ['DAY_OF_WEEK'], inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d7f124f",
   "metadata": {},
   "source": [
    "I want to also deal with potential ouliers. To do this I will apply a <b>Mean and Standard Deviation Method</b>\n",
    "<br><br>\n",
    "> For this outlier detection method, the mean and standard deviation of the residuals are calculated and compared. If a value is a certain number of standard deviations away from the mean, that data point is identified as an outlier. The specified number of standard deviations is called the threshold. The default value is 3.\n",
    "\n",
    "https://docs.oracle.com/cd/E40248_01/epm.1112/cb_statistical/frameset.htm?ch07s02s10s01.html\n",
    "\n",
    "### In order to prepare dataset 'airlines_processed_df_final_2' this step has been skiped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "38513db7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# outliers = ['DISTANCE','PRCP', 'SNOW', 'SNWD', 'TMAX', 'AWND', 'NUMBER_OF_SEATS']\n",
    "\n",
    "# for col in outliers:\n",
    "#     print('Column ', col, ' is being processed...')\n",
    "#     print('Max value now: ', df_final[col].max())\n",
    "#     print('Min value now: ', df_final[col].min())\n",
    "#     print('Count of rows: ', df_final[col].count(), '\\n')\n",
    "    \n",
    "#     df_final = df_final[np.abs(df_final[col]-df_final[col].mean()) <= (3*df_final[col].std())]\n",
    "    \n",
    "#     print('Column ', col, ' processed')\n",
    "#     print('Max value now: ', df_final[col].max())\n",
    "#     print('Min value now: ', df_final[col].min())\n",
    "#     print('Count of rows now: ', df_final[col].count(), '\\n')\n",
    "#     print('#########################################\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eba8cfc",
   "metadata": {},
   "source": [
    "Let's check if there are any nulls left."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ffb2a0a2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_final.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5a8c682c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f031ed8a",
   "metadata": {},
   "source": [
    "Finally, I will use SKLearn's MaxAbsScaler to standarize all the values and convert 'TARGET' column to int type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "670e5133",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "\n",
    "transformer = MaxAbsScaler().fit(df_final)\n",
    "df_transformed = transformer.transform(df_final)\n",
    "\n",
    "columns_names = df_final.columns\n",
    "\n",
    "#final, processed DataFrame\n",
    "df_ready = pd.DataFrame(data = df_transformed, columns = columns_names)\n",
    "df_ready = df_ready = df_ready.astype({'TARGET': 'int32'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "40758ce1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DISTANCE</th>\n",
       "      <th>TARGET</th>\n",
       "      <th>PRCP</th>\n",
       "      <th>SNOW</th>\n",
       "      <th>SNWD</th>\n",
       "      <th>TMAX</th>\n",
       "      <th>AWND</th>\n",
       "      <th>LATITUDE</th>\n",
       "      <th>LONGITUDE</th>\n",
       "      <th>NUMBER_OF_SEATS</th>\n",
       "      <th>...</th>\n",
       "      <th>DEP_TIME_EVENING</th>\n",
       "      <th>DEP_TIME_MORNING</th>\n",
       "      <th>DEP_TIME_NIGHT</th>\n",
       "      <th>DAY_OF_WEEK_1</th>\n",
       "      <th>DAY_OF_WEEK_2</th>\n",
       "      <th>DAY_OF_WEEK_3</th>\n",
       "      <th>DAY_OF_WEEK_4</th>\n",
       "      <th>DAY_OF_WEEK_5</th>\n",
       "      <th>DAY_OF_WEEK_6</th>\n",
       "      <th>DAY_OF_WEEK_7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.01629</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.197384</td>\n",
       "      <td>0.471917</td>\n",
       "      <td>-0.477949</td>\n",
       "      <td>0.148368</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.01629</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.156326</td>\n",
       "      <td>0.471917</td>\n",
       "      <td>-0.477949</td>\n",
       "      <td>0.148368</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.01629</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.565217</td>\n",
       "      <td>0.244830</td>\n",
       "      <td>0.471917</td>\n",
       "      <td>-0.477949</td>\n",
       "      <td>0.148368</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.01629</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.486957</td>\n",
       "      <td>0.530718</td>\n",
       "      <td>0.471917</td>\n",
       "      <td>-0.477949</td>\n",
       "      <td>0.148368</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.01629</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.391304</td>\n",
       "      <td>0.401460</td>\n",
       "      <td>0.471917</td>\n",
       "      <td>-0.477949</td>\n",
       "      <td>0.148368</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   DISTANCE  TARGET  PRCP  SNOW  SNWD      TMAX      AWND  LATITUDE  \\\n",
       "0   0.01629       0   0.0   0.0   0.0  0.600000  0.197384  0.471917   \n",
       "1   0.01629       0   0.0   0.0   0.0  0.600000  0.156326  0.471917   \n",
       "2   0.01629       0   0.0   0.0   0.0  0.565217  0.244830  0.471917   \n",
       "3   0.01629       0   0.0   0.0   0.0  0.486957  0.530718  0.471917   \n",
       "4   0.01629       0   0.0   0.0   0.0  0.391304  0.401460  0.471917   \n",
       "\n",
       "   LONGITUDE  NUMBER_OF_SEATS  ...  DEP_TIME_EVENING  DEP_TIME_MORNING  \\\n",
       "0  -0.477949         0.148368  ...               0.0               0.0   \n",
       "1  -0.477949         0.148368  ...               0.0               0.0   \n",
       "2  -0.477949         0.148368  ...               0.0               0.0   \n",
       "3  -0.477949         0.148368  ...               0.0               0.0   \n",
       "4  -0.477949         0.148368  ...               0.0               0.0   \n",
       "\n",
       "   DEP_TIME_NIGHT  DAY_OF_WEEK_1  DAY_OF_WEEK_2  DAY_OF_WEEK_3  DAY_OF_WEEK_4  \\\n",
       "0             0.0            0.0            0.0            0.0            0.0   \n",
       "1             0.0            1.0            0.0            0.0            0.0   \n",
       "2             0.0            0.0            1.0            0.0            0.0   \n",
       "3             0.0            0.0            0.0            1.0            0.0   \n",
       "4             0.0            0.0            0.0            0.0            1.0   \n",
       "\n",
       "   DAY_OF_WEEK_5  DAY_OF_WEEK_6  DAY_OF_WEEK_7  \n",
       "0            0.0            0.0            1.0  \n",
       "1            0.0            0.0            0.0  \n",
       "2            0.0            0.0            0.0  \n",
       "3            0.0            0.0            0.0  \n",
       "4            0.0            0.0            0.0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ready.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7741a560",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a90be1",
   "metadata": {},
   "source": [
    "Above DataFrame can now be registered as an Azure ML Dataset and used to train the models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc2b491",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8224975e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get my default datastore\n",
    "default_ds = ws.get_default_datastore()\n",
    "\n",
    "#register dataset in Azure ML\n",
    "#dataset = Dataset.Tabular.register_pandas_dataframe(df_ready, default_ds, \"airlines_processed_dataset\", show_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b438c0dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating arguments.\n",
      "Arguments validated.\n",
      "Successfully obtained datastore reference and path.\n",
      "Uploading file to managed-dataset/a5e343cc-ba07-4955-9f18-faf7a7fe7474/\n",
      "Successfully uploaded file to datastore.\n",
      "Creating and registering a new dataset.\n",
      "Successfully created and registered a new dataset.\n"
     ]
    }
   ],
   "source": [
    "#save df_final as a dataset\n",
    "dataset = Dataset.Tabular.register_pandas_dataframe(df_ready, default_ds, \"airlines_processed_df_final_2\", show_progress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f59cf4bf",
   "metadata": {},
   "source": [
    "Next step in the <b>Auto ML Notebook</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda266fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
