{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63721e6c",
   "metadata": {},
   "source": [
    "# <center>Deployment</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeb2e496",
   "metadata": {},
   "source": [
    "### Connect to the workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "293cf524",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready to use Azure ML 1.44.0 to work with avanade-airline-delays\n"
     ]
    }
   ],
   "source": [
    "import azureml.core\n",
    "from azureml.core import Workspace\n",
    "\n",
    "# Load the workspace from the saved config file\n",
    "ws = Workspace.from_config()\n",
    "print('Ready to use Azure ML {} to work with {}'.format(azureml.core.VERSION, ws.name))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06ff5bcf",
   "metadata": {},
   "source": [
    "Let's check if the model is registered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a7636f2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "airline_delays_classification_2 version: 1\n",
      "\t Training context : Auto ML\n",
      "\t Task : Classification\n",
      "\t Objective : Avanade Challenge\n",
      "\t AUC : 0.6865246130797511\n",
      "\t Accuracy : 0.8259597752362156\n",
      "\t F1_score : 0.7685567757525456\n",
      "\n",
      "\n",
      "airline_delays_classification version: 1\n",
      "\t Training context : Auto ML\n",
      "\t Task : Classification\n",
      "\t Objective : Avanade Challenge\n",
      "\t AUC : 0.6865246130797511\n",
      "\t Accuracy : 0.8259597752362156\n",
      "\t F1_score : 0.7685567757525456\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Model\n",
    "\n",
    "for model in Model.list(ws):\n",
    "    print(model.name, 'version:', model.version)\n",
    "    for tag_name in model.tags:\n",
    "        tag = model.tags[tag_name]\n",
    "        print ('\\t',tag_name, ':', tag)\n",
    "    for prop_name in model.properties:\n",
    "        prop = model.properties[prop_name]\n",
    "        print ('\\t',prop_name, ':', prop)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f636fd2",
   "metadata": {},
   "source": [
    "Model needs to be assigned to the variable in order to be deployed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "deb01254",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(workspace=Workspace.create(name='avanade-airline-delays', subscription_id='a0f61829-e513-45af-b347-0542a63713cd', resource_group='moja_resource_grupa'), name=airline_delays_classification, id=airline_delays_classification:1, version=1, tags={'Training context': 'Auto ML', 'Task': 'Classification', 'Objective': 'Avanade Challenge'}, properties={'AUC': '0.6865246130797511', 'Accuracy': '0.8259597752362156', 'F1_score': '0.7685567757525456'})"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ws.models['airline_delays_classification']\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "250f22e8",
   "metadata": {},
   "source": [
    "Now, let's create a folder for the configuration files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8fa24b9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./airlines_delays_deploy_dir folder created.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Create a folder for the deployment and model files\n",
    "deployment_folder = './airlines_delays_deploy_dir'\n",
    "model_folder = './airlines_delays_deploy_dir/Model'\n",
    "os.makedirs(deployment_folder, exist_ok=True)\n",
    "print(deployment_folder, 'folder created.')\n",
    "\n",
    "# Set path for scoring script\n",
    "script_file = 'score_airlines.py'\n",
    "script_path = os.path.join(deployment_folder,script_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e33ecb",
   "metadata": {},
   "source": [
    "And the script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "81663288",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./airlines_delays_deploy_dir/score_airlines.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $script_path\n",
    "import json\n",
    "import joblib\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Called when the service is loaded\n",
    "def init():\n",
    "    global model\n",
    "    # Get the path to the deployed model file and load it\n",
    "    model_path = os.path.join('./airlines_delays_deploy_dir/Model', 'model.pkl')\n",
    "    model = joblib.load(model_path)\n",
    "\n",
    "# Called when a request is received\n",
    "def run(raw_data):\n",
    "    # Get the input data as a numpy array\n",
    "    data = np.array(json.loads(raw_data)['data'])\n",
    "    # Get a prediction from the model\n",
    "    predictions = model.predict(data)\n",
    "    # Get the corresponding classname for each prediction (0 or 1)\n",
    "    classnames = ['on-time', 'delayed']\n",
    "    predicted_classes = []\n",
    "    for prediction in predictions:\n",
    "        predicted_classes.append(classnames[prediction])\n",
    "    # Return the predictions as JSON\n",
    "    return json.dumps(predicted_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab211b50",
   "metadata": {},
   "source": [
    "### Create enviroment file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5eb04171",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./airlines_delays_deploy_dir/deploy_env.yml\n"
     ]
    }
   ],
   "source": [
    "%%writefile $deployment_folder/deploy_env.yml\n",
    "name: deploy_environment\n",
    "dependencies:\n",
    "- python=3.8.5\n",
    "- pip:\n",
    "  - azureml-train-automl-runtime==1.46.1\n",
    "  - inference-schema\n",
    "  - azureml-interpret==1.46.0\n",
    "  - azureml-defaults==1.46.0\n",
    "- numpy==1.21.6\n",
    "- pandas==1.1.5\n",
    "- scikit-learn==0.22.1\n",
    "- py-xgboost==1.3.3\n",
    "- fbprophet==0.7.1\n",
    "- holidays==0.10.3\n",
    "- psutil==5.9.0\n",
    "channels:\n",
    "- anaconda\n",
    "- conda-forge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ac831eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Environment\n",
    "\n",
    "deploy_env = Environment.from_conda_specification(\"deployt_env\", deployment_folder + \"/deploy_env.yml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b9a848",
   "metadata": {},
   "source": [
    "### Configuring the scoring environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "37af3ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.model import InferenceConfig\n",
    "\n",
    "inference_config = InferenceConfig(source_directory=deployment_folder,\n",
    "                                   entry_script=script_file,\n",
    "                                   environment=deploy_env)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4809d4a",
   "metadata": {},
   "source": [
    "### Configuring the web service container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "119223db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deploying model...\n",
      "Tips: You can try get_logs(): https://aka.ms/debugimage#dockerlog or local deployment: https://aka.ms/debugimage#debug-locally to debug if deployment takes longer than 10 minutes.\n",
      "Running\n",
      "2022-10-26 06:47:14+00:00 Creating Container Registry if not exists.\n",
      "2022-10-26 06:47:16+00:00 Use the existing image.\n",
      "2022-10-26 06:47:16+00:00 Generating deployment configuration.\n",
      "2022-10-26 06:47:19+00:00 Submitting deployment to compute..\n",
      "2022-10-26 06:47:23+00:00 Checking the status of deployment airline-service..\n",
      "2022-10-26 06:57:18+00:00 Checking the status of inference endpoint airline-service.\n",
      "Succeeded\n",
      "ACI service creation operation finished, operation \"Succeeded\"\n",
      "Healthy\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.webservice import AciWebservice\n",
    "\n",
    "deployment_config = AciWebservice.deploy_configuration(cpu_cores=1, memory_gb=1)\n",
    "\n",
    "# Deploy the model as a service\n",
    "print('Deploying model...')\n",
    "service_name = \"airline-service\"\n",
    "service = Model.deploy(ws, service_name, [model], inference_config, deployment_config, overwrite=True)\n",
    "service.wait_for_deployment(True)\n",
    "print(service.state)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f55081ea",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3ccdfe2",
   "metadata": {},
   "source": [
    "### Test the deployed service"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "194694ef",
   "metadata": {},
   "source": [
    "This is the schema in which data has to be passed to the created service in order to receive prediction whether the flight can be deleyed or on-time. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "120642d4",
   "metadata": {},
   "source": [
    "|DISTANCE|PRCP|SNOW|SNWD|TMAX|AWND|LATITUDE|LONGITUDE|NUMBER_OF_SEATS|DEP_TIME_AFTERNOON|DEP_TIME_EVENING|DEP_TIME_MORNING|DEP_TIME_NIGHT|DAY_OF_WEEK_1|DAY_OF_WEEK_2|DAY_OF_WEEK_3|DAY_OF_WEEK_4|DAY_OF_WEEK_5|DAY_OF_WEEK_6|DAY_OF_WEEK_7|\n",
    "|-----|------|---|----|----|----|----|----|----|----|----|----|----|----|----|----|----|----|----|----|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f5a21a9",
   "metadata": {},
   "source": [
    "Here, I want to see if data can reach the service and make a single prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "127ee813",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flight data: [0.016, 0.038, 0, 0, 0.417, 0.245, 0.472, -0.478, 0.148, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]\n",
      "on-time\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "x_new = [[0.016, 0.038, 0, 0, 0.417, 0.245, 0.472, -0.478, 0.148, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0 ]]\n",
    "print ('Flight data: {}'.format(x_new[0]))\n",
    "\n",
    "# Convert the array to a serializable list in a JSON document\n",
    "input_json = json.dumps({\"data\": x_new})\n",
    "\n",
    "# Call the web service, passing the input data (the web service will also accept the data in binary format)\n",
    "predictions = service.run(input_data = input_json)\n",
    "\n",
    "# Get the predicted class - it'll be the first (and only) one.\n",
    "predicted_classes = json.loads(predictions)\n",
    "print(predicted_classes[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dcd50ab",
   "metadata": {},
   "source": [
    "Now let's get the endpoint's URI and check if it's possible to make HTTP requests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0bed62a3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://846677fa-0f08-49fe-a96c-514e42465291.westeurope.azurecontainer.io/score\n"
     ]
    }
   ],
   "source": [
    "endpoint = service.scoring_uri\n",
    "print(endpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3a949f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint = 'http://846677fa-0f08-49fe-a96c-514e42465291.westeurope.azurecontainer.io/score'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c24b7e44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flight [0.016, 0.038, 0, 0, 0.417, 0.245, 0.472, -0.478, 0.148, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1] on-time\n",
      "Flight [0.032, 0.032, 1, 0, 0.317, 0.645, 0.377, -0.178, 0.162, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0] delayed\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "x_new = [[0.016, 0.038, 0, 0, 0.417, 0.245, 0.472, -0.478, 0.148, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1 ],\n",
    "         [0.032, 0.032, 1, 0, 0.317, 0.645, 0.377, -0.178, 0.162, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0 ]]\n",
    "\n",
    "# Convert the array to a serializable list in a JSON document\n",
    "input_json = json.dumps({\"data\": x_new})\n",
    "\n",
    "# Set the content type\n",
    "headers = { 'Content-Type':'application/json' }\n",
    "\n",
    "predictions = requests.post(endpoint, input_json, headers = headers)\n",
    "predicted_classes = json.loads(predictions.json())\n",
    "\n",
    "for i in range(len(x_new)):\n",
    "    print (\"Flight {}\".format(x_new[i]), predicted_classes[i] )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cbedd1e",
   "metadata": {},
   "source": [
    "Looks like service has been successfully deployed and requests can be sent without any problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a4a8cf5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
